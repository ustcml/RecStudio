url: ~
user_id_field: &u user_id:token # TODO: comments for &u and *u
item_id_field: &i item_id:token
rating_field: &r rating:float
time_field: &t timestamp:float
time_format: ~

encoding_method: utf-8

inter_feat_name: ~
inter_feat_field: [*u, *i, *r, *t]
inter_feat_header: ~

user_feat_name: ~
user_feat_field: [[*u, age:token, gender:token, occupation:token]]
user_feat_header: ~


item_feat_name: ~
item_feat_field: [[*i, movie_title:token_seq:" ", release_year:token, class:token_seq:" "]]
item_feat_header: ~


field_separator: "\t"
min_user_inter: 0
min_item_inter: 0
field_max_len: ~      # a YAML-format dict, for example
# field_max_len:
#   age: 1
#   gender: 1
#   occupation: 1
low_rating_thres: ~   # low rating threshold, which is used for drop low rating interactions
# drop_low_rating: True # if true, the interactions with rating lower than `rating_thres` would be dropped.

# negative rating threshold, interactions with rating below than the threshold would be regarded as negative interactions.
# Note that when `drop_low_rating` is True, only interactions with rating above `low_rating_thres` and below `negative_rating_thres`
# would be regared as negative interactions.
# The threshold value should be larger than `low_rating_thres`. If not, the threshold would be invalid, which means all interactions kept
# would be regarded as positives.
# negative_rating_thres: 0.0

# `binarized_rating` controls whether to binarize the rating to 0/1 with the `rating_thres`.
# If true, ratings above `rating_thres` would be mapped as 1 and ratings above `rating_thres` would be mapped as 0;
# If false, the ratings would not be changed
binarized_rating_thres: ~

drop_dup: True
max_seq_len: 20

# network feature, including social network and knowledge graph, the first two fields are remapped the corresponding features
network_feat_name: ~ #[[social.txt], [ml-100k.kg, ml-100k.link]]
mapped_feat_field: [*u, *i]
network_feat_field: [[[source_id:token, target_id:token]], [[head_id:token, tail_id:token, relation_id:token], [*i, entity_id:token]]]
network_feat_header: [0, 0]

# sklearn.preprocessing (Arguments supportable; args are sepped with blankspace; same with tuple)
# MinMaxScaler(), StandardScaler(), RobustScaler(), MaxAbsScaler()
# Binarizer(), KBinsDiscretizer(encode="ordinal")
# Normalizer()
# KernelCenterer()
# QuantileTransformer(), SplineTransformer()
# Customized: LogTransformer(), or use FunctionTransformer(...)
float_field_preprocess: ~ # [float_field:MinMaxScaler(), ...]

save_cache: False # whether to save processed dataset to cache.
